}
# if there are no more children to evaluate, then there is an error in the logical pathway of the tree.
if(i > length(parent$children)) stop("Error: cannot solve this data point. Check for errors in the tree")
# otherwise, get the next node down and start evaluating again
node = parent$children[[i]]
}
return(node$name)
}
out
unlist(out)
data <- na.omit(df.spatialdata)[1:50,]
tree <- tr.hsg
if(ncores == "auto") ncores <- parallel::detectCores() - 2
if (ncores > 1) {
cl <- parallel::makeCluster(ncores)
cat("Running parallel with", ncores, "cores")
doParallel::registerDoParallel(cl)
on.exit(try(stopCluster(cl)))
} else {
print("Running sequentially")
foreach::registerDoSEQ()
}
out <- foreach(iter(data)) %dopar%{
require(data.tree)
parent = tree$root # parent holds the set of nodes to be evaluated; start as the root.
descend = F # when descend becomes true, the function has found the right path to follow and will look at the next set of siblings down
i = 1 # each child node of the current parent will be evaluated in turn, referred to by index "i"
node = parent$children[[i]] # node holds the exact logical node to be evaluated, the i'th node of parent
while(!isLeaf(node))  { # when the node is a leaf (end node), the function is done
# extract the name of the variable to evaluate
varname = node$var
# check to see if its in the input data
if(!(varname %in% colnames(data))) {
stop(paste(varname, "must be a column name in input data"))
}
# extract the value
value = data[,varname]
# if the value is na, this point can't be evaluated due to missing data
if(is.na(value) & !grepl("is.na", node$logical)) return(NA)
# change the logical string to use the generic 'value' instead of the specified variable name
# specific variable names are used in the tree objects for readability
lstr = gsub(varname, "value", node$logical)
# evaluate the logical string, storing T/F to 'descend'
descend = eval(parse(text = lstr))
# if descend is true, then this is the correct path. Set the current node as the parent, and start over!
if(descend) {
parent = node
i = 1
# if descend is false, check the next sibling node at this level
} else {
i = i + 1
}
# if there are no more children to evaluate, then there is an error in the logical pathway of the tree.
if(i > length(parent$children)) stop("Error: cannot solve this data point. Check for errors in the tree")
# otherwise, get the next node down and start evaluating again
node = parent$children[[i]]
}
return(node$name)
}
out
unlist(out)
ncores <- 1
stop(cat("Cannot run with", ncores, "as your computer only has", detectCores(), "cores."))
stop(cat("Cannot run with", ncores, "cores as your computer only has", detectCores()))
# Decision tree evaluation for data.tree
# Joe Brehm
# Last edited 8/31/2020
# this function evaluates decision trees stored as data.tree type objects
# input requirements are fairly specific: see the associated tree creation files for how to create trees that can work here
# TO DO:
## rewrite the NA checks so that it string searches the entire set of sibling evaluations -- so you don't need !is.na() everywhere
## better error reporting:
#### "cannot solve" to include where in the tree it is looking
### test params
#load("E:\\NMSU\\datatree-hsg.rdata")
#load("E:\\NMSU\\tree_eval_testdata.rdata")
#ncores <- 1
#require(data.tree)
#require(foreach)
#require(doParallel)
#data <- na.omit(df.spatialdata)[1:50,]
#tree <- tr.hsg
tree_eval <- function(
tree,
# tree is a data tree object structured with classifications as leaves
# above those, all nodes must contain these attributes:
# "var", specifying the variable name to evaluate,
# "logical", specifying the logical evaluation at that step. MUST INCLUDE THE SAME VARIABLE "VAR"
data,
# data must be a data frame containing columns with names matching all the values of "var" used in the tree object
ncores = 1
# number of cores to parallelize over.
# if set to 1 (default), runs sequentially
# Also accepts "auto" as input. Will run with ncores on computer - 2
){
if(ncores == "auto") {
if(detectCores() == 2) {
ncores = 1
} else {
ncores <- parallel::detectCores() - 2
}
}
if(ncores > detectCores()){
stop(cat("Cannot run with", ncores, "cores as your computer only has", detectCores()))
}
if (ncores > 1) {
cl <- parallel::makeCluster(ncores)
cat("Running parallel with", ncores, "cores")
doParallel::registerDoParallel(cl)
on.exit(try(stopCluster(cl)))
} else {
print("Running sequentially")
foreach::registerDoSEQ()
}
out <- foreach(iter(data)) %dopar%{
require(data.tree)
parent = tree$root # parent holds the set of nodes to be evaluated; start as the root.
descend = F # when descend becomes true, the function has found the right path to follow and will look at the next set of siblings down
i = 1 # each child node of the current parent will be evaluated in turn, referred to by index "i"
node = parent$children[[i]] # node holds the exact logical node to be evaluated, the i'th node of parent
while(!isLeaf(node))  { # when the node is a leaf (end node), the function is done
# extract the name of the variable to evaluate
varname = node$var
# check to see if its in the input data
if(!(varname %in% colnames(data))) {
stop(paste(varname, "must be a column name in input data"))
}
# extract the value
value = data[,varname]
# if the value is na, this point can't be evaluated due to missing data
if(is.na(value) & !grepl("is.na", node$logical)) return(NA)
# change the logical string to use the generic 'value' instead of the specified variable name
# specific variable names are used in the tree objects for readability
lstr = gsub(varname, "value", node$logical)
# evaluate the logical string, storing T/F to 'descend'
descend = eval(parse(text = lstr))
# if descend is true, then this is the correct path. Set the current node as the parent, and start over!
if(descend) {
parent = node
i = 1
# if descend is false, check the next sibling node at this level
} else {
i = i + 1
}
# if there are no more children to evaluate, then there is an error in the logical pathway of the tree.
if(i > length(parent$children)) stop("Error: cannot solve this data point. Check for errors in the tree")
# otherwise, get the next node down and start evaluating again
node = parent$children[[i]]
}
return(node$name)
}
return(unlist(out))
}
#library(soilDB)
#library(RODBC)
library(XML)
library(mgcv)
library(mgcViz)
library(splines)
setwd("E:/NMSU/interpretation-engine")
# source local functions
source('local-functions.R')
# load cached data
load('cached-NASIS-data.Rda')
### extract one of the arbitrary curves ####
e.storieC <- evals[evals$evalname == '*Storie Factor C Slope 0 to 100%', ]
#library(soilDB)
#library(RODBC)
library(XML)
library(mgcv)
library(mgcViz)
library(splines)
setwd("E:/NMSU/interpretation-engine")
# source local functions
source('local-functions.R')
# load cached data
load('cached-NASIS-data.Rda')
### extract one of the arbitrary curves ####
e.storieC <- evals[evals$evalname == '*Storie Factor C Slope 0 to 100%', ]
plotEvaluation(e.storieC, xlim=c(0, 200)) # this shows a plot. Saving creates a null obj
## get xy data
s.storieC <- seq(0, 200, length.out = 1000)
f.storieC <- extractEvalCurve(e.storieC)
xy.storieC <- data.frame(cbind(domain=s.storieC, fuzzy.rating=f.storieC(s.storieC)))
xy.storieC
plot(xy.storieC)
#### write a gam
gam.storieC <- gam(fuzzy.rating ~ s(domain), data=xy.storieC)
plot(getViz(gam.storieC), add = T)
plot(xy.storieC)
### predict from the gam
xy.storieC$predict <- predict(gam.storieC, newdata = xy.storieC)
# visual comparison
plot(predict ~ domain, data = xy.storieC)
points(x = xy.storieC$domain,
y = xy.storieC$fuzzy.rating)
## crawdad moistness, obvs
e.crawdad <- evals[evals$evalname == 'CRAWDAD_DRYANDMOISTMO', ]
plotEvaluation(e.crawdad) # this shows a plot. Saving creates a null obj
## get xy data
s.crawdad <- seq(0, 2, length.out = 1000) ### changing the range for this sequence is the only thing that needs to change
f.crawdad <- extractEvalCurve(e.crawdad)
## crawdad moistness, obvs
e.crawdad <- evals[evals$evalname == 'CRAWDAD_DRYANDMOISTMO', ]
plotEvaluation(e.crawdad) # this shows a plot. Saving creates a null obj
## get xy data
s.crawdad <- seq(0, 2, length.out = 1000) ### changing the range for this sequence is the only thing that needs to change
f.crawdad <- extractEvalCurve(e.crawdad)
xy.crawdad <- data.frame(cbind(domain=s.crawdad,
fuzzy.rating=f.crawdad(s.crawdad)))
xy.crawdad
plot(xy.crawdad)
#### write a gam
b.crawdad <- gam(fuzzy.rating ~ s(domain), data=xy.crawdad)
plot(getViz(b.crawdad), add = T)
plot(xy.crawdad)
### predict from the gam
xy.crawdad$predict <- predict(b.crawdad, newdata = xy.crawdad)
# visual comparison
plot(predict ~ domain, data = xy.crawdad)
points(x = xy.crawdad$domain,
y = xy.crawdad$fuzzy.rating)
### wrap into function ####
fuzzgammer <- function(evalname, seq = c(-100,100), tbl = evals, points = T, writegam = T) {
e <- tbl[tbl$evalname == evalname, ]
s <- seq(seq[1], seq[2], length.out = 100)
f <- extractEvalCurve(e)
if(writegam == F) {
plotEvaluation(e)
return(f)
}
fuzz <- f(s)
if(is.null(fuzz)) {
print("No fuzzy rating found for this function. Here's the eval curve instead")
return(f)
}
xy <-
data.frame(cbind(
domain = s,
fuzzy.rating = fuzz
))
b <- gam(fuzzy.rating ~ s(domain),
data = xy)
xy$predict <- predict(b, newdata = xy)
plot(predict ~ domain, data = xy, type = "l")
if(points){
xy <- xy[seq(1, nrow(xy), length.out = 30), ]
points(x = xy$domain,
y = xy$fuzzy.rating,
col = "red",
pch = 16)
}
return(b)
}
testgam <- fuzzgammer(evalname = '*Storie Factor C Slope 0 to 100%', seq = c(0, 100), points = T)
testeval <- fuzzgammer(evalname = '*Storie Factor C Slope 0 to 100%', seq = c(0, 200), points = T, writegam = F)
# test for all types of eval
unique(evals$evaluationtype)
# crisp -- does not work. "curve type not yet supported" may have something to do with this
evals[evals$evaluationtype == "Crisp", "evalname"]
fuzzgammer(evalname = "Ponding Duration < Brief", seq = c(-50, 50))
# works for sigmoid
evals[evals$evaluationtype == "Sigmoid", "evalname"]
fuzzgammer(evalname = "Surface Sand", seq = c(75,85))
# linear works
evals[evals$evaluationtype == "Linear", "evalname"]
fuzzgammer(evalname = "Crusting Index", seq = c(-0, 2))
# arbitrary linear works with some rounding of corners
evals[evals$evaluationtype == "ArbitraryLinear", "evalname"]
fuzzgammer(evalname = "Months With Frequent Ponding", seq = c(0, 3))
# trapezoid is confusing
evals[evals$evaluationtype == "Trapezoid", "evalname"]
fuzzgammer(evalname = "Wetness Masscap", seq = c(10, 35))
### hang on do these actually predict outside their ranges
fout <- fuzzgammer('*Storie Factor C Slope 0 to 100%', seq = c(0, 100))
fout
plot(predict(fout, newdata = data.frame(domain = seq(-100, 200, length.out = 100))))
plot(predict(fout, newdata = data.frame(domain = seq(0, 100, length.out = 100))))
#### hang on how is this different from the f(s) stuff
plot(f.crawdad(seq(-1, 3, length.out = 1000)))
##### TRY GETTING DWB ####
evals[grep("Basement", evals$evalname),]
# 0   Load packages, define workspace, load data ####
require(tidyverse)
rm(list = ls())
# load weg prep and calc functions
setwd("E:\\NMSU")
require(soilDB)
# 1 get data to work with ####
asym <- c("UT684")
source("Functions/pull_SDA.r")
# 1 get data to work with ####
asym <- c("UT684")
l.t <- pull_SDA(asym)
# 1 get data to work with ####
asym <- c("UT685")
l.t <- pull_SDA(asym)
summary(l.t$component)
# source local functions
source('local-functions.R')
# load cached data
load('cached-NASIS-data.Rda')
setwd("E:/NMSU/interpretation-engine")
# source local functions
source('local-functions.R')
# load cached data
load('cached-NASIS-data.Rda')
evals[evals$evalname == "DEPTH TO BEDROCK HARD (Modality - representative value)"]
View(evals)
# Quick SDA data acquisition
# Joe Brehm
# last edited 10/13/2020
# This function is a shortcut for loading in a broad set of SDA data, filtered to area symbols specified by an input character vector
# Other than filtering by area symbol, no modifications are made to the data
# at last edit, these tables are returned:
## legend
## mapunit
## component
## chorizon
## corestrictions
## cosurffrags
## cotaxfmmin
## codiagfeatures
## comonth
## chtexturegrp
## chfrags
## chtexture
## cosoilmoist
## muaggatt
## chunified
require(soilDB)
require(tidyverse)
pull_SDA <- function(asym){
ls.tables.sda <- list()
asym <- paste0("('", paste0(asym, collapse = "', '"), "')") # convert from character vector to a text string SDA_query can parse
#for all queries:
## get a list of keys in the selected area symbols
## attach data from the specified tables
## don't forget to left join when subordinate to component
## then drop the far left column, which is a duplicate key column
### tables above or parallel component ####
ls.tables.sda[["legend"]] <-
soilDB::SDA_query(paste0(
"SELECT *
FROM legend
WHERE areasymbol IN", asym))
ls.tables.sda[["mapunit"]] <-
soilDB::SDA_query(paste0(
"WITH m AS (SELECT mukey
FROM legend
INNER JOIN mapunit ON mapunit.lkey = legend.lkey
WHERE areasymbol IN", asym, ")
SELECT *
FROM m
INNER JOIN mapunit ON m.mukey = mapunit.mukey")) %>%
dplyr::select(-1)
ls.tables.sda[["component"]] <-
soilDB::SDA_query(paste0(
"WITH c AS (SELECT cokey
FROM legend
INNER JOIN mapunit ON mapunit.lkey = legend.lkey
INNER JOIN component ON component.mukey = mapunit.mukey
WHERE areasymbol IN", asym, ")
SELECT *
FROM c
INNER JOIN component ON c.cokey = component.cokey")) %>%
dplyr::select(-1)
### tables beneath component ####
ls.tables.sda[["chorizon"]] <-
soilDB::SDA_query(paste0(
"WITH c AS (SELECT cokey
FROM legend
INNER JOIN mapunit ON mapunit.lkey = legend.lkey
INNER JOIN component ON component.mukey = mapunit.mukey
WHERE areasymbol IN", asym, ")
SELECT *
FROM c
LEFT JOIN chorizon ON c.cokey = chorizon.cokey")) %>%
dplyr::select(-1)
ls.tables.sda[["corestrictions"]] <-
soilDB::SDA_query(paste0(
"WITH c AS (SELECT cokey
FROM legend
INNER JOIN mapunit ON mapunit.lkey = legend.lkey
INNER JOIN component ON component.mukey = mapunit.mukey
WHERE areasymbol IN", asym, ")
SELECT *
FROM c
LEFT JOIN corestrictions ON c.cokey = corestrictions.cokey")) %>%
dplyr::select(-1)
ls.tables.sda[["cosurffrags"]] <-
soilDB::SDA_query(paste0(
"WITH c AS (SELECT cokey
FROM legend
INNER JOIN mapunit ON mapunit.lkey = legend.lkey
INNER JOIN component ON component.mukey = mapunit.mukey
WHERE areasymbol IN", asym, ")
SELECT *
FROM c
LEFT JOIN cosurffrags ON c.cokey = cosurffrags.cokey")) %>%
dplyr::select(-1)
ls.tables.sda[["cotaxfmmin"]] <-
soilDB::SDA_query(paste0(
"WITH c AS (SELECT cokey
FROM legend
INNER JOIN mapunit ON mapunit.lkey = legend.lkey
INNER JOIN component ON component.mukey = mapunit.mukey
WHERE areasymbol IN", asym, ")
SELECT *
FROM c
LEFT JOIN cotaxfmmin ON c.cokey = cotaxfmmin.cokey")) %>%
dplyr::select(-1)
ls.tables.sda[["codiagfeatures"]] <-
soilDB::SDA_query(paste0(
"WITH c AS (SELECT cokey
FROM legend
INNER JOIN mapunit ON mapunit.lkey = legend.lkey
INNER JOIN component ON component.mukey = mapunit.mukey
WHERE areasymbol IN", asym, ")
SELECT *
FROM c
LEFT JOIN codiagfeatures ON c.cokey = codiagfeatures.cokey")) %>%
dplyr::select(-1)
ls.tables.sda[["comonth"]] <-
soilDB::SDA_query(paste0(
"WITH c AS (SELECT cokey
FROM legend
INNER JOIN mapunit ON mapunit.lkey = legend.lkey
INNER JOIN component ON component.mukey = mapunit.mukey
WHERE areasymbol IN", asym, ")
SELECT *
FROM c
LEFT JOIN comonth ON c.cokey = comonth.cokey")) %>%
dplyr::select(-1)
### tables beneath chorizon ####
ls.tables.sda[["chtexturegrp"]] <-
soilDB::SDA_query(paste0(
"WITH ch AS (SELECT chkey
FROM legend
INNER JOIN mapunit ON mapunit.lkey = legend.lkey
INNER JOIN component ON component.mukey = mapunit.mukey
LEFT JOIN chorizon ON chorizon.cokey = component.cokey
WHERE areasymbol IN", asym, ")
SELECT *
FROM ch
LEFT JOIN chtexturegrp ON ch.chkey = chtexturegrp.chkey")) %>%
dplyr::select(-1)
ls.tables.sda[["chfrags"]] <-
soilDB::SDA_query(paste0(
"WITH ch AS (SELECT chkey
FROM legend
INNER JOIN mapunit ON mapunit.lkey = legend.lkey
INNER JOIN component ON component.mukey = mapunit.mukey
LEFT JOIN chorizon ON chorizon.cokey = component.cokey
WHERE areasymbol IN", asym, ")
SELECT *
FROM ch
LEFT JOIN chfrags ON ch.chkey = chfrags.chkey")) %>%
dplyr::select(-1)
ls.tables.sda[["chunified"]] <-
soilDB::SDA_query(paste0(
"WITH ch AS (SELECT chkey
FROM legend
INNER JOIN mapunit ON mapunit.lkey = legend.lkey
INNER JOIN component ON component.mukey = mapunit.mukey
LEFT JOIN chorizon ON chorizon.cokey = component.cokey
WHERE areasymbol IN", asym, ")
SELECT *
FROM ch
LEFT JOIN chunified ON ch.chkey = chunified.chkey")) %>%
dplyr::select(-1)
### other tables ####
ls.tables.sda[["chtexture"]] <-
soilDB::SDA_query(paste0(
"WITH chtg AS (SELECT chtgkey
FROM legend
INNER JOIN mapunit ON mapunit.lkey = legend.lkey
INNER JOIN component ON component.mukey = mapunit.mukey
LEFT JOIN chorizon ON chorizon.cokey = component.cokey
LEFT JOIN chtexturegrp ON chorizon.chkey = chtexturegrp.chkey
WHERE areasymbol IN", asym, ")
SELECT *
FROM chtg
LEFT JOIN chtexture ON chtg.chtgkey = chtexture.chtgkey")) %>%
dplyr::select(-1)
ls.tables.sda[["cosoilmoist"]] <-
soilDB::SDA_query(paste0(
"WITH com AS (SELECT comonthkey
FROM legend
INNER JOIN mapunit ON mapunit.lkey = legend.lkey
INNER JOIN component ON component.mukey = mapunit.mukey
LEFT JOIN comonth ON comonth.cokey = component.cokey
WHERE areasymbol IN", asym, ")
SELECT *
FROM com
LEFT JOIN cosoilmoist ON com.comonthkey = cosoilmoist.comonthkey")) %>%
dplyr::select(-1)
ls.tables.sda[["muaggatt"]] <-
soilDB::SDA_query(paste0(
"WITH m AS (SELECT mukey
FROM legend
INNER JOIN mapunit ON mapunit.lkey = legend.lkey
WHERE areasymbol IN", asym, ")
SELECT *
FROM m
INNER JOIN muaggatt ON m.mukey = muaggatt.mukey")) %>%
dplyr::select(-1)
### end ####
return(ls.tables.sda)
}
l.t <- pull_SDA(asym)
l.t$chunified
