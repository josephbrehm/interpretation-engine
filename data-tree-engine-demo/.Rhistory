source("tree_eval.r")
# view interp trees
# logical holds the precise logical statement defining each node
print(tr.hsg, "logical")
print(tr.svi, "logical")
# var is the name of the variable used by that node -- required for how tree_eval is written currently
# "classification" is assigned to leaf nodes. It isn't actually required, or ever referred to. Could be any name, or NA
print(tr.hsg, "var")
print(tr.svi, "var")
# load raster brick, all preprocessed already
load("DuchesneHU100_treecalcBrick_InData.rdata")
# names have to be these, exactly. Order doesn't matter. Extra layers in the brick are fine
names(brk.in) <- c("wt", "rl", "kw", "ksat", "slope")
### 1 run the tree evaluation ####
brk.out <- brk.in
# run sequentially
t1 <- Sys.time()
brk.out$hsg <-
tree_eval(tree = tr.hsg,
data = brk.in,
ncores = 1)
t2 <- Sys.time()
print(t2 - t1)
### 0 load packages, workspace, functions, and data ####
library(rgdal)
library(tidyverse)
library(rgeos)
library(rasterVis)
library(parallel)
library(foreach)
# set working directory
setwd("E:/NMSU/interpretation-engine/data-tree-engine-demo")
# load data.tree engine functions
load("datatree_hsg.rdata") # loads tr.hsg
load("datatree_svi.rdata") # loads tr.svi
source("tree_eval.r")
# view interp trees
# logical holds the precise logical statement defining each node
print(tr.hsg, "logical")
print(tr.svi, "logical")
# var is the name of the variable used by that node -- required for how tree_eval is written currently
# "classification" is assigned to leaf nodes. It isn't actually required, or ever referred to. Could be any name, or NA
print(tr.hsg, "var")
print(tr.svi, "var")
# load raster brick, all preprocessed already
load("DuchesneHU100_treecalcBrick_InData.rdata")
# names have to be these, exactly. Order doesn't matter. Extra layers in the brick are fine
names(brk.in) <- c("wt", "rl", "kw", "ksat", "slope")
### 1 run the tree evaluation ####
brk.out <- brk.in
# run sequentially
t1 <- Sys.time()
brk.out$hsg <-
tree_eval(tree = tr.hsg,
indata = brk.in,
ncores = 1)
t2 <- Sys.time()
print(t2 - t1)
# Decision tree evaluation for data.tree
# Joe Brehm
# Last edited 10/10/2020
# this function evaluates decision trees stored as data.tree type objects
# input requirements are fairly specific: see the associated tree creation files for how to create trees that can work here
## Update 9/24/2020:
### internal parallelization! set ncores = 1 for sequential; ncores = "auto" or ncores = [number] for parallel
## update 10/20/2020
### will try to as() the "data" input to a data frame, rather than requiring it to be a dataframe. (Will work for bricks now)
# TO DO:
## internal raster acceptance. Currently requires rasters be converted to a brick then to a data frame
## rewrite the NA checks so that it string searches the entire set of sibling evaluations -- so you don't need !is.na() everywhere
## better error reporting:
### "cannot solve" error to include where in the tree it is looking
## make it faster! calc?
### Rewrite each level to return "go to path 1/2/3/etc" rather than T (descend) or F (go sideways and do another logical)
require(parallel)
require(data.tree)
require(foreach)
require(doParallel)
tree_eval <- function(
tree,
# tree is a data tree object structured with classifications as leaves
# above those, all nodes must contain these attributes:
# "var", specifying the variable name to evaluate,
# "logical", specifying the logical evaluation at that step. MUST INCLUDE THE SAME VARIABLE "VAR"
indata,
# data must be a data frame containing columns with names matching all the values of "var" used in the tree object
ncores = 1
# number of cores to parallelize over.
# if set to 1 (default), runs sequentially
# Also accepts "auto" as input. Will run with ncores on computer - 2
){
# if class is raster brick, convert it to a dataframe. Calc may be faster
## if class is a stack, brick then df.
if (class(indata)[1] != "data.frame") {
indata <- as.data.frame(indata)
}
# auto core counting: use n cores in computer, minus 2
if(ncores == "auto") {
if(detectCores() == 2) { # just in case there's a dual core machine out there
ncores = 1
} else {
ncores <- parallel::detectCores() - 2
}
}
# check if user requested too many cores for the machine
if(ncores > detectCores()){
stop(cat("Cannot run with", ncores, "cores as your computer only has", detectCores()))
}
# register sequential or parallel backend, depending on ncores
if (ncores > 1) {
cat("Running parallel with", ncores, "cores")
cl <- parallel::makeCluster(ncores)
doParallel::registerDoParallel()
} else {
cat("Running sequentially")
foreach::registerDoSEQ()
}
out <- foreach(row = 1:nrow(indata),
.packages = "data.tree"
) %dopar% {
parent = tree$root # parent holds the set of nodes to be evaluated; start as the root.
descend = F # when descend becomes true, the function has found the right path to follow and will look at the next set of siblings down
i = 1 # each child node of the current parent will be evaluated in turn, referred to by index "i"
node = parent$children[[i]] # node holds the exact logical node to be evaluated, the i'th node of parent
while(!isLeaf(node))  { # when the node is a leaf (end node), the function is done
# extract the name of the variable to evaluate
varname = node$var
# check to see if its in the input data
if(!(varname %in% colnames(indata))) {
stop(paste(varname, "must be a column name in input data"))
}
# extract the value
value = indata[row,varname]
# if the value is na, this point can't be evaluated due to missing data
if(is.na(value) & !grepl("is.na", node$logical)) return(NA)
# change the logical string to use the generic 'value' instead of the specified variable name
# specific variable names are used in the tree objects for readability
lstr = gsub(varname, "value", node$logical)
# evaluate the logical string, storing T/F to 'descend'
descend = eval(parse(text = lstr))
# if descend is true, then this is the correct path. Set the current node as the parent, and start over!
if(descend) {
parent = node
i = 1
# if descend is false, check the next sibling node at this level
} else {
i = i + 1
}
# if there are no more children to evaluate, then there is an error in the logical pathway of the tree.
if(i > length(parent$children)) stop("Error: cannot solve this data point. Check for errors in the tree")
# otherwise, get the next node down and start evaluating again
node = parent$children[[i]]
}
return(node$name)
}
if(ncores > 1) stopCluster(cl)
return(unlist(out))
}
brk.out$hsg <-
tree_eval(tree = tr.hsg,
indata = brk.in,
ncores = 1)
t1 <- Sys.time()
brk.out$hsg <-
tree_eval(tree = tr.hsg,
indata = brk.in,
ncores = 1)
t2 <- Sys.time()
print(t2 - t1)
t3 <- Sys.time()
brk.out$hsg <-
tree_eval(tree = tr.hsg,
indata = brk.in,
ncores = "auto")
t4 <- Sys.time()
# need to get the shortHSG data --
df.spatialdata$shorthsg <-
sapply(df.spatialdata$hsg,
function(h){
strsplit(h,
"/")[[1]][1]
})
### 1 run the tree evaluation ####
### 1.1 - HSG
df.out <- data.frame(brk.in)
### 1 run the tree evaluation ####
### 1.1 - HSG
df.out <- as.data.frame(brk.in)
# run sequentially on a raster
t1 <- Sys.time()
brk.out$hsg <-
tree_eval(tree = tr.hsg,
indata = df.out,
ncores = 1)
t2 <- Sys.time()
print(t2 - t1)
# run parallel
t3 <- Sys.time()
brk.out$hsg <-
tree_eval(tree = tr.hsg,
indata = df.out,
ncores = "auto")
t4 <- Sys.time()
raster("Duchesne100100_ksat_ut_60.100_4clip.tif")
raster("E:/NMSU/Bricklayer Processing/Duchesne100100_ksat_ut_60.100_4clip.tif")
### 0 workspace and run params ####
library(rgdal)
library(tidyverse)
library(rgeos)
library(beepr)
library(rasterVis)
library(parallel)
library(foreach)
setwd("E:/NMSU/")
# set master CRS (albers conus, 102003)
crs <- crs("+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=37.5 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs")
# get manageable size study area (Duchesne hydro unit, in NE Utah)
shp.all <- rgdal::readOGR(dsn = "GIS",
layer = "HUnit8_UT") %>%
spTransform(crs)
shp <- subset(shp.all,
HU_8_NAME == "Duchesne")
outname <- "Duchesne100100" ## outname is used to save / load files from different study areas / resolutions, for testing
rm(shp.all)
# shp.all <- rgdal::readOGR(dsn = "GIS/Utah_County_Boundaries-shp",
#                   layer = "Counties") %>%
#   spTransform(crs)
#
# shp <- subset(shp.all, NAME == "SAN JUAN")
# shp <- subset(shp.all, NAME == "GRAND")
#
# outname <- "sanjuan100"
# outname <- "Grand500"
#
# #shp <- shp.all
plot(shp)
# set raster resolution
res <- c(100, 100)
# set list of raster paths to import
l.r <- list("Data/wtdept_ut.tif",
"Data/resdept_r_cm_2D_QRF.tif",
"Data/kwfact_0_cm_2D_QRF.tif",
"Data/ksat_ut/ksat_ut_0-5.tif",
"Data/ksat_ut/ksat_ut_5-15.tif",
"Data/ksat_ut/ksat_ut_15-30.tif",
"Data/ksat_ut/ksat_ut_30-60.tif",
"Data/ksat_ut/ksat_ut_60-100.tif",
"Data/ksat_ut/ksat_ut_100-200.tif",
"Data/slope_pct_ut.tif")
#ksat rasters are in log10 cm/h
### 1 generic raster processing with bricklayer ####
source("Functions/bricklayer.r")
brk <- bricklayer(l.r = l.r,
crs = crs,
shp = shp,
res = res,
verbose = T,
saveIntermediates = T,
useIntermediates = T,
dirIntermediates = "Bricklayer Processing",
prefix = outname)
beepr::beep()
names(brk) <- c("wt", "rl", "kw", "ksat0", "ksat5", "ksat15", "ksat30", "ksat60", "ksat100", "slope")
brk.ksat <- brk[[c("ksat0", "ksat5", "ksat15", "ksat30", "ksat60", "ksat100")]]
# if there is an rl above the depth interval, we do not use that data
brk.ksat$ksat100[brk$rl < 100] <- NA # 100-200
brk.ksat$ksat60[brk$rl < 60] <- NA # 60-100
brk.ksat$ksat30[brk$rl < 30] <- NA # 30-60
brk.ksat$ksat15[brk$rl < 15] <- NA # 15-30
brk.ksat$ksat5[brk$rl < 5] <- NA # 5-15
# merge depth limited ksat rasters, finding min
brk$ksat_cmh <-
merge(brk.ksat,
fun = min)
# convert ksat from log-cm/h to um/s
brk$ksat <-
calc(brk$ksat_cmh,
fun = function(x) 10^x * 10000 / 3600) # cm/h to um/s: 10000um/cm, 3600s/hr
plot(brk$ksat)
load("Engine Guts/datatree-hsg.rdata")
load("Engine Guts/datatree-svi.rdata")
source("Functions/tree_eval.r")
brk.subset <- brk[[c("wt", "rl", "kw", "ksat", "slope")]]
df.spatialdata <- as.data.frame(brk.subset)
head(na.omit(df.spatialdata))
#### TIME TRIAL 1 ####
t1 <- Sys.time()
if(file.exists(paste0("tree_eval_", outname, "_hsg-svi.rdata"))) { # load both svi and hsg if you can
load (paste0("tree_eval_", outname, "_hsg-svi.rdata"))
} else {
# try loading just hsg
if(file.exists(paste0("tree_eval_", outname, "_hsg.rdata"))){
load(paste0("tree_eval_", outname, "_hsg.rdata"))
} else {
df.spatialdata$hsg <-
tree_eval(tr.hsg,
df.spatialdata,
ncores = 1)
beep()
save(df.spatialdata, file = paste0("tree_eval_", outname, "_hsg.rdata"))
}
df.spatialdata$shorthsg <-
sapply(df.spatialdata$hsg,
function(h){
strsplit(h,
"/")[[1]][1]
})
df.spatialdata$svi <-
tree_eval(tr.svi,
df.spatialdata,
ncores = 1)
beep(3)
save(df.spatialdata, paste0("tree_eval_", outname, "_hsg-svi.rdata"))
}
df.out <- na.omit(df.out)
### 1 run the tree evaluation ####
### 1.1 - HSG
df.out <- as.data.frame(brk.in)
### 0 load packages, workspace, functions, and data ####
library(rgdal)
library(tidyverse)
library(rgeos)
library(rasterVis)
library(parallel)
library(foreach)
# set working directory
setwd("E:/NMSU/interpretation-engine/data-tree-engine-demo")
# load data.tree engine functions
load("datatree_hsg.rdata") # loads tr.hsg
load("datatree_svi.rdata") # loads tr.svi
source("tree_eval.r")
# view interp trees
# logical holds the precise logical statement defining each node
print(tr.hsg, "logical")
print(tr.svi, "logical")
# var is the name of the variable used by that node -- required for how tree_eval is written currently
# "classification" is assigned to leaf nodes. It isn't actually required, or ever referred to. Could be any name, or NA
print(tr.hsg, "var")
print(tr.svi, "var")
# load raster brick, all preprocessed already
load("DuchesneHU100_treecalcBrick_InData.rdata")
# names have to be these, exactly. Order doesn't matter. Extra layers in the brick are fine
names(brk.in) <- c("wt", "rl", "kw", "ksat", "slope")
### 1 run the tree evaluation ####
### 1.1 - HSG
df.out <- as.data.frame(brk.in)
df.out <- na.omit(df.out)
t1 <- Sys.time()
out <-
tree_eval(tree = tr.hsg,
indata = df.out,
ncores = 1)
t2 <- Sys.time()
print(t2 - t1)
df.out
# Decision tree evaluation for data.tree
# Joe Brehm
# Last edited 10/10/2020
# this function evaluates decision trees stored as data.tree type objects
# input requirements are fairly specific: see the associated tree creation files for how to create trees that can work here
## Update 9/24/2020:
### internal parallelization! set ncores = 1 for sequential; ncores = "auto" or ncores = [number] for parallel
## update 10/20/2020
### will try to as() the "data" input to a data frame, rather than requiring it to be a dataframe. (Will work for bricks now)
# TO DO:
## internal raster acceptance. Currently requires rasters be converted to a brick then to a data frame
## rewrite the NA checks so that it string searches the entire set of sibling evaluations -- so you don't need !is.na() everywhere
## better error reporting:
### "cannot solve" error to include where in the tree it is looking
## make it faster! calc?
### Rewrite each level to return "go to path 1/2/3/etc" rather than T (descend) or F (go sideways and do another logical)
require(parallel)
require(data.tree)
require(foreach)
require(doParallel)
tree_eval <- function(
tree,
# tree is a data tree object structured with classifications as leaves
# above those, all nodes must contain these attributes:
# "var", specifying the variable name to evaluate,
# "logical", specifying the logical evaluation at that step. MUST INCLUDE THE SAME VARIABLE "VAR"
indata,
# data must be a data frame containing columns with names matching all the values of "var" used in the tree object
ncores = 1
# number of cores to parallelize over.
# if set to 1 (default), runs sequentially
# Also accepts "auto" as input. Will run with ncores on computer - 2
){
# if class is raster brick, convert it to a dataframe. Calc may be faster
## if class is a stack, brick then df.
if (class(indata)[1] != "data.frame") {
indata <- as.data.frame(indata)
}
# auto core counting: use n cores in computer, minus 2
if(ncores == "auto") {
if(detectCores() == 2) { # just in case there's a dual core machine out there
ncores = 1
} else {
ncores <- parallel::detectCores() - 2
}
}
# check if user requested too many cores for the machine
if(ncores > detectCores()){
stop(cat("Cannot run with", ncores, "cores as your computer only has", detectCores()))
}
# register sequential or parallel backend, depending on ncores
if (ncores > 1) {
cat("Running parallel with", ncores, "cores")
cl <- parallel::makeCluster(ncores)
doParallel::registerDoParallel()
} else {
cat("Running sequentially")
foreach::registerDoSEQ()
}
out <- foreach(row = 1:nrow(indata),
.packages = "data.tree"
) %dopar% {
parent = tree$root # parent holds the set of nodes to be evaluated; start as the root.
descend = F # when descend becomes true, the function has found the right path to follow and will look at the next set of siblings down
i = 1 # each child node of the current parent will be evaluated in turn, referred to by index "i"
node = parent$children[[i]] # node holds the exact logical node to be evaluated, the i'th node of parent
while(!isLeaf(node))  { # when the node is a leaf (end node), the function is done
# extract the name of the variable to evaluate
varname = node$var
# check to see if its in the input data
if(!(varname %in% colnames(indata))) {
stop(paste(varname, "must be a column name in input data"))
}
# extract the value
value = indata[row,varname]
# if the value is na, this point can't be evaluated due to missing data
if(is.na(value) & !grepl("is.na", node$logical)) return(NA)
# change the logical string to use the generic 'value' instead of the specified variable name
# specific variable names are used in the tree objects for readability
lstr = gsub(varname, "value", node$logical)
# evaluate the logical string, storing T/F to 'descend'
descend = eval(parse(text = lstr))
# if descend is true, then this is the correct path. Set the current node as the parent, and start over!
if(descend) {
parent = node
i = 1
# if descend is false, check the next sibling node at this level
} else {
i = i + 1
}
# if there are no more children to evaluate, then there is an error in the logical pathway of the tree.
if(i > length(parent$children)) stop("Error: cannot solve this data point. Check for errors in the tree")
# otherwise, get the next node down and start evaluating again
node = parent$children[[i]]
}
return(node$name)
}
if(ncores > 1) stopCluster(cl)
# if(class(indata)[2] == "raster"){
#   out <- raster(unlist(out), indata[[1]])
# }
return(unlist(out))
}
brk.subset <- brk[[c("wt", "rl", "kw", "ksat", "slope")]]
df.spatialdata <- as.data.frame(brk.subset)
head(na.omit(df.spatialdata))
#### TIME TRIAL 1 ####
t1 <- Sys.time()
if(file.exists(paste0("tree_eval_", outname, "_hsg-svi.rdata"))) { # load both svi and hsg if you can
load (paste0("tree_eval_", outname, "_hsg-svi.rdata"))
} else {
# try loading just hsg
if(file.exists(paste0("tree_eval_", outname, "_hsg.rdata"))){
load(paste0("tree_eval_", outname, "_hsg.rdata"))
} else {
df.spatialdata$hsg <-
tree_eval(tr.hsg,
df.spatialdata,
ncores = 1)
beep()
save(df.spatialdata, file = paste0("tree_eval_", outname, "_hsg.rdata"))
}
df.spatialdata$shorthsg <-
sapply(df.spatialdata$hsg,
function(h){
strsplit(h,
"/")[[1]][1]
})
df.spatialdata$svi <-
tree_eval(tr.svi,
df.spatialdata,
ncores = 1)
beep(3)
save(df.spatialdata, paste0("tree_eval_", outname, "_hsg-svi.rdata"))
}
df.out <- as.data.frame(brk.in)
df.out <- na.omit(d)
# run sequentially on a raster
t1 <- Sys.time()
out <-
tree_eval(tree = tr.hsg,
indata = df.out,
ncores = 1)
t2 <- Sys.time()
print(t2 - t1)
### 1 run the tree evaluation ####
### 1.1 - HSG
df.out <- as.data.frame(brk.in)
df.out <- na.omit(df.out)
# run sequentially on a raster
t1 <- Sys.time()
out <-
tree_eval(tree = tr.hsg,
indata = df.out,
ncores = 1)
t2 <- Sys.time()
print(t2 - t1)
